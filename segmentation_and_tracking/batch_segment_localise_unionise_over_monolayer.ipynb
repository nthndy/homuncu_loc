{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "443c3842",
   "metadata": {},
   "source": [
    "# LoC localisation notebook - batch process\n",
    "\n",
    "This notebook loads a set of images and segments them based on a \"segmentation channel\" of choice. The structure of the notebook is as follows:\n",
    "\n",
    "1. Load images\n",
    "2. Segment\n",
    "3. Localise segment centroids\n",
    "4. Unite cell slices over z-stack (equivalent to track over t)\n",
    "5. Check labelling in Napari"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ef9a9b",
   "metadata": {},
   "source": [
    "Load necessary Python packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0403fd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2019 NVIDIA Corporation\n",
      "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
      "Cuda compilation tools, release 10.1, V10.1.243\n",
      "Thu Aug 17 14:21:14 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.105.01   Driver Version: 515.105.01   CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A6000    On   | 00000000:65:00.0  On |                  Off |\n",
      "| 30%   43C    P8    33W / 300W |    799MiB / 49140MiB |     12%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A    248106      G   /usr/lib/xorg/Xorg                332MiB |\n",
      "|    0   N/A  N/A    248664      G   /usr/bin/gnome-shell               63MiB |\n",
      "|    0   N/A  N/A    298293      G   ...AAAAAAAAA= --shared-files       61MiB |\n",
      "|    0   N/A  N/A    453820      G   ...032443910155199331,262144      184MiB |\n",
      "|    0   N/A  N/A    453826      G   ...veSuggestionsOnlyOnDemand      151MiB |\n",
      "+-----------------------------------------------------------------------------+\n",
      ">>> GPU activated? YES\n"
     ]
    }
   ],
   "source": [
    "import os # this module contains functions for interacting with the operating system (i.e. list files etc)\n",
    "import glob # good for finding files matching a certain extension\n",
    "from skimage import io #scikit image data in/out module (for loading/saving images)\n",
    "import napari # image viewer\n",
    "import matplotlib.pyplot as plt # figure making module, used to display two images side by side\n",
    "from tqdm import tqdm # this is a counter that times how long iterative jobs take\n",
    "import numpy as np # this numerical python module is good for handling images as matrices\n",
    "import btrack # this is for \"tracking\" cells through the z-axis\n",
    "from homuncu_loc import tools # this is for a few custom tools \n",
    "import h5py # for creating an empty h5 placeholder file\n",
    "# from macrohet import notify\n",
    "\n",
    "# print gpu information\n",
    "!nvcc --version\n",
    "!nvidia-smi\n",
    "\n",
    "# load cellpose\n",
    "from cellpose import core, utils, models, metrics\n",
    "\n",
    "# check to see if GPU can be used\n",
    "use_GPU = core.use_gpu()\n",
    "yn = ['NO', 'YES']\n",
    "print(f'>>> GPU activated? {yn[use_GPU]}')\n",
    "\n",
    "# define segmentation model parameters\n",
    "model = models.Cellpose(gpu=use_GPU, \n",
    "                        model_type='cyto') # cytoplasmic segmentation \n",
    "channels = [0,0] # this means using a grayscale image for both nuclei and cyto channels (even if not using nuclei, still have to say its same colour [greyscale = 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017be436",
   "metadata": {},
   "source": [
    "## 1. Load images\n",
    "\n",
    "The first step here is to define a base directory where different images for analysis are stored. By defining the path to this directory as a python variable we will reduce the need for long string input of future image paths. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6794d0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the experimental data sets contained within base_dir:\n",
      "['run2_23-02-104', 'run1_23-01-001_23-01-005', 'run3']\n"
     ]
    }
   ],
   "source": [
    "# take note of root directories on server and local equivalent for saving of dir structure locally\n",
    "base_dir = server_rootdir = '/run/user/30046150/gvfs/smb-share:server=data2.thecrick.org,share=lab-gutierrezm/home/shared/Lung on Chip/image analysis_Nathan/Job_Mtb area'\n",
    "# this is the root directory where files will be saved locally\n",
    "local_rootdir = '/home/dayn/data/homuncu_loc_temp'\n",
    "print('Here are the experimental data sets contained within base_dir:')\n",
    "print(os.listdir(base_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f2246c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the image data sets contained within the base directory:\n",
      "run2_23-02-104/48h pi/20230718_20X_23-02-104B2_Multichannel Z-Stack_20230718_1365.tif\n",
      "run2_23-02-104/48h pi/20230718_20X_23-02-104B2_Multichannel Z-Stack_20230718_1363.tif\n",
      "run2_23-02-104/48h pi/20230718_20X_23-02-104B2_Multichannel Z-Stack_20230718_1361.tif\n",
      "run2_23-02-104/48h pi/20230718_20X_23-02-104B2_Multichannel Z-Stack_20230718_1362.tif\n",
      "run2_23-02-104/48h pi/20230718_20X_23-02-104B2_Multichannel Z-Stack_20230718_1364.tif\n",
      "run2_23-02-104/2h pi/20230714_20X_23-02-104A4_Multichannel Z-Stack_20230714_1343.tif\n",
      "run2_23-02-104/2h pi/20230714_20X_23-02-104A4_Multichannel Z-Stack_20230714_1342.tif\n",
      "run2_23-02-104/2h pi/20230714_20X_23-02-104A4_Multichannel Z-Stack_20230714_1344.tif\n",
      "run2_23-02-104/2h pi/20230714_20X_23-02-104A4_Multichannel Z-Stack_20230714_1341.tif\n",
      "run2_23-02-104/2h pi/20230714_20X_23-02-104A4_Multichannel Z-Stack_20230714_1340.tif\n",
      "run1_23-01-001_23-01-005/48h pi/20230707_40X_23-01-005A3_Multichannel Z-Stack_20230707_1325.tif\n",
      "run1_23-01-001_23-01-005/48h pi/20230707_40X_23-01-005A3_Multichannel Z-Stack_20230707_1324.tif\n",
      "run1_23-01-001_23-01-005/48h pi/20230705_40X_23-01-005A3_Multichannel Z-Stack_20230705_1309.tif\n",
      "run1_23-01-001_23-01-005/48h pi/20230705_40X_23-01-005A3_Multichannel Z-Stack_20230705_1306.tif\n",
      "run1_23-01-001_23-01-005/48h pi/20230705_40X_23-01-005A3_Multichannel Z-Stack_20230705_1308.tif\n",
      "run1_23-01-001_23-01-005/48h pi/20230705_40X_23-01-005A3_Multichannel Z-Stack_20230705_1307.tif\n",
      "run1_23-01-001_23-01-005/48h pi/20230705_40X_23-01-005A3_Multichannel Z-Stack_20230705_1311.tif\n",
      "run1_23-01-001_23-01-005/48h pi/20230705_40X_23-01-005A3_Multichannel Z-Stack_20230705_1310.tif\n",
      "run1_23-01-001_23-01-005/2h pi/20230707_40X_23-01-001A3_Multichannel Z-Stack_20230707_1318.tif\n",
      "run1_23-01-001_23-01-005/2h pi/20230707_40X_23-01-001A3_Multichannel Z-Stack_20230707_1319.tif\n",
      "run1_23-01-001_23-01-005/2h pi/20230707_40X_23-01-001A3_Multichannel Z-Stack_20230707_1317.tif\n",
      "run1_23-01-001_23-01-005/2h pi/20230707_40X_23-01-001A3_Multichannel Z-Stack_20230707_1313.tif\n",
      "run1_23-01-001_23-01-005/2h pi/20230707_40X_23-01-001A3_Multichannel Z-Stack_20230707_1316.tif\n",
      "run1_23-01-001_23-01-005/2h pi/20230707_40X_23-01-001A3_Multichannel Z-Stack_20230707_1315.tif\n",
      "run1_23-01-001_23-01-005/2h pi/20230707_40X_23-01-001A3_Multichannel Z-Stack_20230707_1320.tif\n",
      "run1_23-01-001_23-01-005/2h pi/20230707_40X_23-01-001A3_Multichannel Z-Stack_20230707_1314.tif\n",
      "run3/23-03-002/20230801_20X_23-03-002A6_DAPI_SP-C_PDPN_ZO-1_Multichannel Z-Stack_20230801_1444.tif\n",
      "run3/23-03-002/20230801_20X_23-03-002A5_DAPI_NKX201_PDPN_ZO-1_Multichannel Z-Stack_20230801_1441.tif\n",
      "run3/23-03-011/20230801_20X_23-03-011B5_DAPI_NKX2-1_PDPN_ZO-1_Multichannel Z-Stack_20230801_1434.tif\n"
     ]
    }
   ],
   "source": [
    "print('Here are the image data sets contained within the base directory:')\n",
    "image_file_list = list()\n",
    "\n",
    "for root, dirs, files in os.walk(base_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.tif'):\n",
    "            image_file_list.append(os.path.join(root, file))\n",
    "\n",
    "for image_file in image_file_list:\n",
    "    folder_up = os.path.relpath(os.path.dirname(image_file), base_dir)\n",
    "    file_name = os.path.basename(image_file)\n",
    "    print(f'{folder_up}/{file_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a495c0",
   "metadata": {},
   "source": [
    "Next we will pick some specific images to do, one image per directory to begin with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6203601",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting one image from each directory:\n",
      "run2_23-02-104/48h pi/20230718_20X_23-02-104B2_Multichannel Z-Stack_20230718_1365.tif\n",
      "run2_23-02-104/2h pi/20230714_20X_23-02-104A4_Multichannel Z-Stack_20230714_1343.tif\n",
      "run1_23-01-001_23-01-005/48h pi/20230707_40X_23-01-005A3_Multichannel Z-Stack_20230707_1325.tif\n",
      "run1_23-01-001_23-01-005/2h pi/20230707_40X_23-01-001A3_Multichannel Z-Stack_20230707_1318.tif\n",
      "run3/23-03-002/20230801_20X_23-03-002A6_DAPI_SP-C_PDPN_ZO-1_Multichannel Z-Stack_20230801_1444.tif\n",
      "run3/23-03-011/20230801_20X_23-03-011B5_DAPI_NKX2-1_PDPN_ZO-1_Multichannel Z-Stack_20230801_1434.tif\n"
     ]
    }
   ],
   "source": [
    "print('Selecting one image from each directory:')\n",
    "image_file_list = list()\n",
    "unique_folders = set()\n",
    "# collect file names (one per )\n",
    "for root, dirs, files in os.walk(base_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.tif'):\n",
    "            folder_path = os.path.dirname(os.path.join(root, file))\n",
    "            if folder_path not in unique_folders:\n",
    "                unique_folders.add(folder_path)\n",
    "                image_file_list.append(os.path.join(root, file))\n",
    "                break  # Move to the next folder after adding one image.\n",
    "\n",
    "# print file names\n",
    "for image_file in image_file_list:\n",
    "    folder_up = os.path.relpath(os.path.dirname(image_file), base_dir)\n",
    "    file_name = os.path.basename(image_file)\n",
    "    print(f'{folder_up}/{file_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4320fd1c",
   "metadata": {},
   "source": [
    "Or filter for images you do not want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c26b6686",
   "metadata": {},
   "outputs": [],
   "source": [
    "IDs = ['1306', # only 3 z slices  \n",
    "       '1343', '1342', '1344', '1341' # ZO1 not quite there\n",
    "      ]\n",
    "\n",
    "# Use a list comprehension to filter the image_file_list and remove filenames containing faulty IDs\n",
    "image_file_list = [fn for fn in image_file_list if not any(ID in fn for ID in IDs)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebcf588-1635-4367-a1c7-3a43a4d7a39e",
   "metadata": {},
   "source": [
    "Or filter for images you DO want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0f7c7b4-dbbc-4c51-a350-9464aacdadef",
   "metadata": {},
   "outputs": [],
   "source": [
    "IDs = ['1434', '1444', '1441'\n",
    "      ]\n",
    "\n",
    "# Use a list comprehension to filter the image_file_list and include filenames containing IDs\n",
    "image_file_list = [fn for fn in image_file_list if any(ID in fn for ID in IDs)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ebab8f",
   "metadata": {},
   "source": [
    "# Batch process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251e91a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7d7c157126e4c6fa2b31e40910b6ef5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterating over images:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded image: run3/23-03-011/20230801_20X_23-03-011B5_DAPI_NKX2-1_PDPN_ZO-1_Multichannel Z-Stack_20230801_1434.tif\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04a2a55a46a148518634f695abe7cba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checking where the cells are in the image stack:   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cefb7f6e5894ac88a4ba9a48c86a68c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Segmenting image stack:   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLPK Integer Optimizer 5.0\n",
      "15724 rows, 12835 columns, 17808 non-zeros\n",
      "12835 integer variables, all of which are binary\n",
      "Preprocessing...\n",
      "7862 rows, 12835 columns, 17808 non-zeros\n",
      "12835 integer variables, all of which are binary\n",
      "Scaling...\n",
      " A: min|aij| =  1.000e+00  max|aij| =  1.000e+00  ratio =  1.000e+00\n",
      "Problem data seem to be well scaled\n",
      "Constructing initial basis...\n",
      "Size of triangular part is 7862\n",
      "Solving LP relaxation...\n",
      "GLPK Simplex Optimizer 5.0\n",
      "7862 rows, 12835 columns, 17808 non-zeros\n",
      "*     0: obj =   4.362128822e+04 inf =   0.000e+00 (2876)\n",
      "Perturbing LP to avoid stalling [1110]...\n",
      "Removing LP perturbation [2745]...\n",
      "*  2745: obj =   2.795048215e+04 inf =   0.000e+00 (0)\n",
      "OPTIMAL LP SOLUTION FOUND\n",
      "Integer optimization begins...\n",
      "Long-step dual simplex will be used\n",
      "+  2745: mip =     not found yet >=              -inf        (1; 0)\n",
      "+  2745: >>>>>   2.795048215e+04 >=   2.795048215e+04   0.0% (1; 0)\n",
      "+  2745: mip =   2.795048215e+04 >=     tree is empty   0.0% (0; 1)\n",
      "INTEGER OPTIMAL SOLUTION FOUND\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2023/08/03 09:50:21 pm] Ending BayesianTracker session\n",
      "03-Aug-23 21:50:21 - btrack.core - INFO     - Ending BayesianTracker session\n",
      "[INFO][2023/08/03 09:50:21 pm] Opening HDF file: /home/dayn/data/homuncu_loc_temp/run2_23-02-104/48h pi/20230718_20X_23-02-104B2_Multichannel Z-Stack_20230718_1365_z_tracks_masks.h5...\n",
      "03-Aug-23 21:50:21 - btrack.io.hdf - INFO     - Opening HDF file: /home/dayn/data/homuncu_loc_temp/run2_23-02-104/48h pi/20230718_20X_23-02-104B2_Multichannel Z-Stack_20230718_1365_z_tracks_masks.h5...\n",
      "[INFO][2023/08/03 09:50:21 pm] Writing objects/obj_type_1\n",
      "03-Aug-23 21:50:21 - btrack.io.hdf - INFO     - Writing objects/obj_type_1\n",
      "[INFO][2023/08/03 09:50:21 pm] Writing labels/obj_type_1\n",
      "03-Aug-23 21:50:21 - btrack.io.hdf - INFO     - Writing labels/obj_type_1\n",
      "[INFO][2023/08/03 09:50:21 pm] Loading objects/obj_type_1 (34822, 5) (34822 filtered: None)\n",
      "03-Aug-23 21:50:21 - btrack.io.hdf - INFO     - Loading objects/obj_type_1 (34822, 5) (34822 filtered: None)\n",
      "[INFO][2023/08/03 09:50:22 pm] Writing properties/obj_type_1/axis_major_length (34822,)\n",
      "03-Aug-23 21:50:22 - btrack.io.hdf - INFO     - Writing properties/obj_type_1/axis_major_length (34822,)\n",
      "[INFO][2023/08/03 09:50:22 pm] Writing properties/obj_type_1/axis_minor_length (34822,)\n",
      "03-Aug-23 21:50:22 - btrack.io.hdf - INFO     - Writing properties/obj_type_1/axis_minor_length (34822,)\n",
      "[INFO][2023/08/03 09:50:22 pm] Writing properties/obj_type_1/eccentricity (34822,)\n",
      "03-Aug-23 21:50:22 - btrack.io.hdf - INFO     - Writing properties/obj_type_1/eccentricity (34822,)\n",
      "[INFO][2023/08/03 09:50:22 pm] Writing properties/obj_type_1/area (34822,)\n",
      "03-Aug-23 21:50:22 - btrack.io.hdf - INFO     - Writing properties/obj_type_1/area (34822,)\n",
      "[INFO][2023/08/03 09:50:22 pm] Writing properties/obj_type_1/orientation (34822,)\n",
      "03-Aug-23 21:50:22 - btrack.io.hdf - INFO     - Writing properties/obj_type_1/orientation (34822,)\n",
      "[INFO][2023/08/03 09:50:22 pm] Writing properties/obj_type_1/mean_intensity (34822, 4)\n",
      "03-Aug-23 21:50:22 - btrack.io.hdf - INFO     - Writing properties/obj_type_1/mean_intensity (34822, 4)\n",
      "[INFO][2023/08/03 09:50:22 pm] Writing properties/obj_type_1/mtb_status (34822,)\n",
      "03-Aug-23 21:50:22 - btrack.io.hdf - INFO     - Writing properties/obj_type_1/mtb_status (34822,)\n",
      "[INFO][2023/08/03 09:50:22 pm] Writing properties/obj_type_1/mtb_area (34822,)\n",
      "03-Aug-23 21:50:22 - btrack.io.hdf - INFO     - Writing properties/obj_type_1/mtb_area (34822,)\n",
      "[INFO][2023/08/03 09:50:22 pm] Writing tracks/obj_type_1\n",
      "03-Aug-23 21:50:22 - btrack.io.hdf - INFO     - Writing tracks/obj_type_1\n",
      "[INFO][2023/08/03 09:50:22 pm] Writing dummies/obj_type_1\n",
      "03-Aug-23 21:50:22 - btrack.io.hdf - INFO     - Writing dummies/obj_type_1\n",
      "[INFO][2023/08/03 09:50:22 pm] Writing LBEP/obj_type_1\n",
      "03-Aug-23 21:50:22 - btrack.io.hdf - INFO     - Writing LBEP/obj_type_1\n",
      "[INFO][2023/08/03 09:50:22 pm] Writing fates/obj_type_1\n",
      "03-Aug-23 21:50:22 - btrack.io.hdf - INFO     - Writing fates/obj_type_1\n",
      "[INFO][2023/08/03 09:50:28 pm] Closing HDF file: /home/dayn/data/homuncu_loc_temp/run2_23-02-104/48h pi/20230718_20X_23-02-104B2_Multichannel Z-Stack_20230718_1365_z_tracks_masks.h5\n",
      "03-Aug-23 21:50:28 - btrack.io.hdf - INFO     - Closing HDF file: /home/dayn/data/homuncu_loc_temp/run2_23-02-104/48h pi/20230718_20X_23-02-104B2_Multichannel Z-Stack_20230718_1365_z_tracks_masks.h5\n"
     ]
    }
   ],
   "source": [
    "# iterate over file list\n",
    "for image_file in tqdm(reversed(image_file_list), total = len(image_file_list), desc = 'Iterating over images'):\n",
    "    # redefine output filename as being h5 file in same directory as image\n",
    "    output_fn = image_file.replace('.tif', '_z_tracks_masks.h5')\n",
    "    # relocate output file to a local directory (doesnt like saving to server?)\n",
    "    output_fn = output_fn.replace(server_rootdir, local_rootdir)\n",
    "    # create directory structure to hold local file\n",
    "    os.makedirs(os.path.dirname(output_fn), exist_ok=True)\n",
    "    # check if output fn exists already, if so then skip\n",
    "    if os.path.exists(output_fn):\n",
    "        print(f'Output {os.path.basename(output_fn)} already exists')\n",
    "        continue\n",
    "    # create empty placeholder file so that other parallel processes do not start on the same image whilst this is processing\n",
    "    else:\n",
    "        # Create an empty HDF5 file with \n",
    "        with h5py.File(output_fn, \"w\") as f:\n",
    "            pass\n",
    "    # load image\n",
    "    try:\n",
    "        image = io.imread(image_file)\n",
    "        if image.ndim < 4:\n",
    "            print('Image is not correct shape')\n",
    "            continue\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while reading the image: {image_file}\")\n",
    "        print(e)\n",
    "    # format filenames to print update\n",
    "    folder_up = os.path.relpath(os.path.dirname(image_file), base_dir)\n",
    "    file_name = os.path.basename(image_file)\n",
    "    # print update\n",
    "    print(f'Loaded image: {folder_up}/{file_name}')\n",
    "    # set zo1 as mask input channel\n",
    "    mask_input_channel = image[...,1]\n",
    "    # check where the cells exist in the image volume, start by defining an empty list to store mean intensity values\n",
    "    mean_measure = list()\n",
    "    # iterate over image data set \n",
    "    for frame in tqdm(mask_input_channel, total = len(mask_input_channel), \n",
    "                      desc = 'Checking where the cells are in the image stack'):\n",
    "        mean_measure.append(np.mean(frame))    \n",
    "    # Calculate the average background signal\n",
    "    average_background = np.mean(mean_measure)\n",
    "    # Find the indices where the signal crosses above and below the average background\n",
    "    start_frame = 0 #np.where(mean_measure > average_background)[0][0] - 5 # adding a buffer\n",
    "    end_frame = len(mask_input_channel) #np.where(mean_measure > average_background)[0][-1] + 5 # adding a buffer \n",
    "    ### define empty mask image array (as a list)\n",
    "    mask_stack = list()\n",
    "    ### iterate over frames\n",
    "    for n, frame in tqdm(enumerate(mask_input_channel), total = len(mask_input_channel), \n",
    "                         desc = 'Segmenting image stack'):\n",
    "        if start_frame < n < end_frame:\n",
    "            ### run segmentation for single frame\n",
    "            masks, flows, styles, diams = model.eval(frame, diameter=None, flow_threshold=None, channels=channels, min_size = 500)\n",
    "            \n",
    "            # trying to fix bug where localisation fails if only one segment present in image\n",
    "            if np.max(masks) < 2:\n",
    "                # if beyond the focal range of the stack then just use blank array as masks\n",
    "                masks = np.zeros(frame.shape, dtype=np.uint16)\n",
    "                \n",
    "        else:\n",
    "            # if beyond the focal range of the stack then just use blank array as masks\n",
    "            masks = np.zeros(frame.shape, dtype=np.uint16)\n",
    "        ### append segmentation results to empty to mask image list\n",
    "        mask_stack.append(masks)\n",
    "    # turn mask stack into an image array\n",
    "    mask_stack = np.stack(mask_stack, axis = 0)\n",
    "    \n",
    "    # define props \n",
    "    props = ('axis_major_length',\n",
    "             'axis_minor_length',\n",
    "             'eccentricity',\n",
    "             'area',\n",
    "             'orientation',\n",
    "             'mean_intensity',\n",
    "             'intensity_image')\n",
    "    \n",
    "    # localise all cells in image stack\n",
    "    objects = btrack.utils.segmentation_to_objects(\n",
    "                                                   segmentation = mask_stack, # set the masks here \n",
    "                                                   intensity_image = image, # provide the image so that the mean intensity can be measured\n",
    "                                                   properties = props, # provide the cell properties to improve tracker \n",
    "                                                   use_weighted_centroid = False, \n",
    "    #                                                    assign_class_ID=True,\n",
    "                                                   )\n",
    "    # check if mtb infected above threshold\n",
    "    threshold = 230\n",
    "    for o in tqdm(objects):\n",
    "        mtb_glimpse = o.properties['intensity_image'][...,3]\n",
    "        mtb_status = np.any(mtb_glimpse > threshold)\n",
    "        mtb_area = np.sum(mtb_glimpse > threshold)\n",
    "        o.properties['mtb_status'] = mtb_status\n",
    "        o.properties['mtb_area'] = mtb_area\n",
    "        del o.properties['intensity_image']\n",
    "    \n",
    "    # apply size threshold\n",
    "    objects = [o for o in objects if o.properties['area'] > 500]\n",
    "    \n",
    "    #redefine tuple of properties to remove intensity image\n",
    "    props = ('axis_major_length',\n",
    "             'axis_minor_length',\n",
    "             'eccentricity',\n",
    "             'area',\n",
    "             'orientation',\n",
    "             'mean_intensity',\n",
    "             )\n",
    "    \n",
    "    print(f'{len(objects)} cell objects found in {len(mask_input_channel)} frames/z-slices')\n",
    "    # track cells over Z\n",
    "    with btrack.BayesianTracker() as tracker:\n",
    "        # configure the tracker using a config file\n",
    "        tracker.configure('/home/dayn/analysis/btrack/models/particle_config.json')\n",
    "        ### set max search radius to a very limited radius \n",
    "        tracker.max_search_radius = 5\n",
    "        # define tracking method\n",
    "        tracker.tracking_updates = [\"MOTION\", \"VISUAL\"]\n",
    "        # use visual features to track\n",
    "        tracker.features = props\n",
    "        # append the objects to be tracked\n",
    "        tracker.append(objects)\n",
    "        # set the volume\n",
    "        tracker.volume=((0, mask_input_channel.shape[1]), (0, mask_input_channel.shape[2]), (-1e5, 1e5))\n",
    "        # track them (in interactive mode)\n",
    "        tracker.track(step_size=10)\n",
    "        # generate hypotheses and run the global optimizer\n",
    "        tracker.optimize()\n",
    "        # get the tracks as a python list\n",
    "        tracks = tracker.tracks\n",
    "    \n",
    "    # save out \n",
    "    with btrack.io.HDF5FileHandler(output_fn, \n",
    "                                       'w', \n",
    "                                       obj_type='obj_type_1'\n",
    "                                       ) as writer:\n",
    "            writer.write_tracks(tracks)\n",
    "            writer.write_segmentation(mask_stack)\n",
    "    # notify me\n",
    "    notify.send_sms(f'{image_file} complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5473c06d",
   "metadata": {},
   "source": [
    "# Check output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a37551c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dayn/analysis/btrack/btrack/dataio.py:3: UserWarning: `btrack.dataio` has been deprecated. Please use `btrack.io` subpackage instead.\n",
      "  warnings.warn(  # noqa: B028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant skips harvesting pyclesperanto as it's not installed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Labels layer 'mask_stack' at 0x7f9bcad0b910>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = napari.Viewer()\n",
    "\n",
    "v.add_image(image, channel_axis = -1, )\n",
    "v.add_labels(mask_stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bc48a5",
   "metadata": {},
   "source": [
    "job1a images/tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d7ce59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File list saved to /home/dayn/data/homuncu_loc_temp/job_1a_files.txt\n"
     ]
    }
   ],
   "source": [
    "file_list = [\n",
    "    \"DAPI-SPC-PDPN-ZO1/Day14_breath/20x_21-12-029B_A12346_Multichannel Z-Stack_20220819_295.tif\",\n",
    "    \"DAPI-SPC-PDPN-ZO1/Day14_static/20x_21-12-028A_A23456_Multichannel Z-Stack_20220818_246.tif\",\n",
    "    \"DAPI-SPC-PDPN-ZO1/Day7_breath/20x_21-12-029A_A3456_Multichannel Z-Stack_20220818_196.tif\",\n",
    "    \"DAPI-SPC-PDPN-ZO1/Day7_static/20x_21-12-031B_A12456_Multichannel Z-Stack_20220811_121.tif\",\n",
    "    \"DAPI-NKX21-PDPN-ZO1/Day14_breath/20x_21-12-029B_A12346_Multichannel Z-Stack_20220819_286.tif\",\n",
    "    \"DAPI-NKX21-PDPN-ZO1/Day14_static/20x_21-12-028A_A23456_Multichannel Z-Stack_20220818_235.tif\",\n",
    "    \"DAPI-NKX21-PDPN-ZO1/Day7_static/20x_21-12-031B_A12456_Multichannel Z-Stack_20220811_113.tif\"\n",
    "]\n",
    "\n",
    "output_file = \"/home/dayn/data/homuncu_loc_temp/job_1a_files.txt\"\n",
    "\n",
    "with open(output_file, \"w\") as file:\n",
    "    for item in file_list:\n",
    "        file.write(\"%s\\n\" % item)\n",
    "\n",
    "print(f\"File list saved to {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brassica",
   "language": "python",
   "name": "brassica"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
